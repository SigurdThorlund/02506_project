{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Imports. Loading data. Definining dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import PIL.Image\n",
    "import os\n",
    "import seaborn as sbn\n",
    "from albumentations import GaussNoise, RandomGridShuffle, Normalize, PixelDropout\n",
    "import elasticdeform\n",
    "from skimage.io import imread, imsave\n",
    "\n",
    "sbn.set()\n",
    "\n",
    "datadir = \"EM_ISBI_CHALLENGE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random image subset\n",
    "np.random.seed(42)\n",
    "validation_subset_idx = [int(x) for x in np.random.rand(5) * 31]\n",
    "validation_subset_idx.sort()\n",
    "\n",
    "train_subset_idx = [x for x in range(1, 31) if x not in validation_subset_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset class.\n",
    "class ChallengeData(torch.utils.data.Dataset):\n",
    "    '''  Dataset which loads all images for training or testing'''\n",
    "    def __init__(self, data_dir, type, margin_size=20):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        if type == 'train':\n",
    "            self.train_set = True\n",
    "            self.test_set = False\n",
    "            self.validation_set = False\n",
    "        elif type == 'test':\n",
    "            self.train_set = False\n",
    "            self.test_set = True\n",
    "            self.validation_set = False\n",
    "        elif type == 'validation':\n",
    "            self.train_set = False\n",
    "            self.test_set = False\n",
    "            self.validation_set = True\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.img_prefix = 'train' if (self.train_set or self.validation_set) else 'test'\n",
    "        self.img_folder = 'train_images' if (self.train_set or self.validation_set) else 'test_images'\n",
    "        self.labels_folder = 'train_labels'\n",
    "        self.labels_prefix = 'labels'\n",
    "        \n",
    "\n",
    "        if self.train_set:\n",
    "            self.load_train_set()\n",
    "        elif self.test_set:\n",
    "            self.load_test_set()\n",
    "        elif self.validation_set:\n",
    "            self.load_validation_set()\n",
    "\n",
    "\n",
    "    def load_train_set(self):\n",
    "        for idx in train_subset_idx:\n",
    "            im = np.array(PIL.Image.open(f'{self.data_dir}/{self.img_folder}/{self.img_prefix}_{idx:02d}.png'))\n",
    "            im = im/255\n",
    "            self.images.append(torch.tensor(im, dtype=torch.float32))\n",
    "\n",
    "            label_im = np.array(PIL.Image.open(f'{self.data_dir}/{self.labels_folder}/{self.labels_prefix}_{idx:02d}.png'))\n",
    "            label_im = label_im/255\n",
    "            # label_im = label_im[margin_size:-margin_size, margin_size:-margin_size]/255\n",
    "            self.labels.append(torch.tensor(label_im, dtype=torch.float32))\n",
    "\n",
    "    def load_validation_set(self):\n",
    "        for idx in validation_subset_idx:\n",
    "            im = np.array(PIL.Image.open(f'{self.data_dir}/{self.img_folder}/{self.img_prefix}_{idx:02d}.png'))\n",
    "            im = im/255\n",
    "            self.images.append(torch.tensor(im, dtype=torch.float32))\n",
    "\n",
    "            label_im = np.array(PIL.Image.open(f'{self.data_dir}/{self.labels_folder}/{self.labels_prefix}_{idx:02d}.png'))\n",
    "            label_im = label_im/255\n",
    "            # label_im = label_im[margin_size:-margin_size, margin_size:-margin_size]/255\n",
    "            self.labels.append(torch.tensor(label_im, dtype=torch.float32))\n",
    "\n",
    "\n",
    "    def load_test_set(self):\n",
    "        for idx in range(1, 31):\n",
    "            im = np.array(PIL.Image.open(f'{self.data_dir}/{self.img_folder}/{self.img_prefix}_{idx:02d}.png'))\n",
    "            im = im/255\n",
    "            self.images.append(torch.tensor(im, dtype=torch.float32))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train_set or self.validation_set:\n",
    "            return self.images[idx], self.labels[idx]\n",
    "        \n",
    "        return self.images[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and validation set.\n",
    "# (This involves loading images and may take some seconds.)\n",
    "challengeTrainData = ChallengeData(datadir, type='train')\n",
    "challengeValidationData = ChallengeData(datadir, type='validation')\n",
    "challengeTestData = ChallengeData(datadir, type='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(challengeTrainData,\n",
    "                                          batch_size=10,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)\n",
    "validationloader = torch.utils.data.DataLoader(challengeValidationData,\n",
    "                                            batch_size=5)\n",
    "testloader = torch.utils.data.DataLoader(challengeTestData,\n",
    "                                          batch_size=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition\n",
    "Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Make model class.\n",
    "class UNet128(torch.nn.Module):\n",
    "    \"\"\"Takes in patches of 128^2 RGB, returns 88^2\"\"\"\n",
    "    \n",
    "    def __init__(self, out_channels=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Learnable\n",
    "        self.conv1A = torch.nn.Conv2d(1, 8, 3)  \n",
    "        self.conv1B = torch.nn.Conv2d(8, 8, 3)  \n",
    "        self.conv2A = torch.nn.Conv2d(8, 16, 3)  \n",
    "        self.conv2B = torch.nn.Conv2d(16, 16, 3)  \n",
    "        self.conv3A = torch.nn.Conv2d(16, 32, 3)  \n",
    "        self.conv3B = torch.nn.Conv2d(32, 32, 3)  \n",
    "        self.conv4A = torch.nn.Conv2d(32, 16, 3)  \n",
    "        self.conv4B = torch.nn.Conv2d(16, 16, 3)  \n",
    "        self.conv5A = torch.nn.Conv2d(16, 8, 3)  \n",
    "        self.conv5B = torch.nn.Conv2d(8, 8, 3)  \n",
    "        self.convfinal = torch.nn.Conv2d(8, out_channels, 1)         \n",
    "        self.convtrans34 = torch.nn.ConvTranspose2d(32, 16, 2, stride=2) \n",
    "        self.convtrans45 = torch.nn.ConvTranspose2d(16, 8, 2, stride=2)\n",
    "        \n",
    "        # Convenience\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)        \n",
    "       \n",
    "    def forward(self, x):\n",
    " \n",
    "        # Down, keeping layer outputs we'll need later.\n",
    "        l1 = self.relu(self.conv1B(self.relu(self.conv1A(x))))\n",
    "        l2 = self.relu(self.conv2B(self.relu(self.conv2A(self.pool(l1)))))\n",
    "        out = self.relu(self.conv3B(self.relu(self.conv3A(self.pool(l2))))) \n",
    "        \n",
    "        # Up, now we overwritte out in each step.\n",
    "        out = torch.cat([self.convtrans34(out), l2[:,:,4:-4,4:-4]], dim=1)\n",
    "        out = self.relu(self.conv4B(self.relu(self.conv4A(out))))\n",
    "        out = torch.cat([self.convtrans45(out), l1[:,:,16:-16,16:-16]], dim=1)      \n",
    "        out = self.relu(self.conv5B(self.relu(self.conv5A(out))))\n",
    "   \n",
    "         # Finishing\n",
    "        out = self.convfinal(out)\n",
    "  \n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training parameters\n",
    "Include here what types of data augmentation we're using. Using weight map or not. Define models and epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 472, 472])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = UNet128()\n",
    "\n",
    "net(torch.zeros(1, 1, 512, 512)).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "Loop for training the model with the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Visualizations of the results for the report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
